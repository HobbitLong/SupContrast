{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import os  \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(identity_selection, save_path, file_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    identity_selection.to_csv(save_path + file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "def get_all_data_csv(data_path):\n",
    "    '''get csv of all data, race, id, image_name'''\n",
    "    coloumns = ['image_name', 'id', 'race']\n",
    "    print(data_path)\n",
    "\n",
    "    df = pd.DataFrame(columns=coloumns)\n",
    "    all_image = []\n",
    "    race_to_label = {'Caucasian': 0, 'Indian': 1, 'Asian': 2, 'African': 3}\n",
    "    label_to_race = {0: 'Caucasian', 1: 'Indian', 2: 'Asian', 3: 'African'}\n",
    "\n",
    "    for race in race_to_label.keys():\n",
    "        race_folder = os.path.join(data_path+'/', race)\n",
    "        print(race_folder)\n",
    "        race_label = race_to_label[race]\n",
    "        for id_folder in os.listdir(race_folder):\n",
    "            if not 'm.' in id_folder:\n",
    "                continue\n",
    "            all_id_image = []\n",
    "\n",
    "            id_path = os.path.join(race_folder, id_folder)\n",
    "            id = id_folder.split(\"/\")[0]\n",
    "\n",
    "            for image in os.listdir(id_path):\n",
    "                all_id_image.append(image)\n",
    "            for image in all_id_image:\n",
    "                all_image.append([image, id, race_label])\n",
    "        \n",
    "    df = pd.DataFrame(all_image, columns=coloumns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_csv = get_all_data_csv(\"./race_per_7000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_per_race(race_df, image_per_id_limit=60, total_img=30000, id_per_race=500):\n",
    "    '''\n",
    "    get a new df with 60 image per id\n",
    "    draw id_per_race uniformly \n",
    "    draw image_per_id uniformly\n",
    "    '''\n",
    "    # Group by ID and count the number of images per ID\n",
    "    data_grouped = race_df.groupby(\"id\").count()\n",
    "    \n",
    "    # Filter IDs with at least 'image_per_id_limit' images\n",
    "    data_grouped = data_grouped[data_grouped[\"image_name\"] >= image_per_id_limit]\n",
    "    \n",
    "    # Get a list of IDs that meet the image count criteria\n",
    "    eligible_ids = data_grouped.index.tolist()\n",
    "    \n",
    "    # Shuffle the list of eligible IDs\n",
    "    random.shuffle(eligible_ids)\n",
    "    \n",
    "    # Take the first 'id_per_race' IDs to ensure uniform distribution\n",
    "    selected_ids = eligible_ids[:id_per_race]\n",
    "    \n",
    "    # Filter the DataFrame to include only rows with selected IDs\n",
    "    filtered_id_df = race_df[race_df[\"id\"].isin(selected_ids)]\n",
    "    \n",
    "    # Randomly sample images from each selected ID to meet the 'total_img' requirement\n",
    "    num_selected_images = 0\n",
    "    selected_rows = []\n",
    "    \n",
    "    for id in selected_ids:\n",
    "        id_df = filtered_id_df[filtered_id_df[\"id\"] == id]\n",
    "        num_images_for_id = min(image_per_id_limit, total_img - num_selected_images)\n",
    "        \n",
    "        # Randomly sample 'num_images_for_id' images for the current ID\n",
    "        sampled_rows = id_df.sample(n=num_images_for_id, random_state=42)\n",
    "        selected_rows.extend(sampled_rows.values)\n",
    "        num_selected_images += num_images_for_id\n",
    "        \n",
    "        if num_selected_images >= total_img:\n",
    "            break\n",
    "    \n",
    "    # Create a new DataFrame from the selected rows\n",
    "    new_df = pd.DataFrame(selected_rows, columns=['image_name', 'id', 'race'])\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced(data, image_per_id_limit=60, total_image=120000, id_per_race=500): \n",
    "    race_to_label = {'Caucasian': 0, 'Indian': 1, 'Asian': 2, 'African': 3}\n",
    "    label_to_race = {0: 'Caucasian', 1: 'Indian', 2: 'Asian', 3: 'African'}\n",
    "\n",
    "    balanced_data = pd.DataFrame()\n",
    "\n",
    "    for race in race_to_label.keys():\n",
    "        race_label = race_to_label[race]\n",
    "        cur_race_data = data[data['race']==race_label]\n",
    "        race_balanced_df = get_balanced_per_race(cur_race_data, image_per_id_limit, total_image, id_per_race)\n",
    "        balanced_data = pd.concat([balanced_data, race_balanced_df])\n",
    "    \n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = get_balanced(data, 60, 120000, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(balanced_data))\n",
    "print(balanced_data.head())\n",
    "print(balanced_data.groupby('id').count()['image_name'])\n",
    "print(balanced_data.groupby('race').count()['image_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(balanced_data, \"./\", \"balanced_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out balanced data and get disjoint_balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = pd.read_csv(\"./balanced_data.csv\")\n",
    "data = pd.read_csv(\"./all_data.csv\")\n",
    "#filter out everything in balanced_data\n",
    "filtered_data = data[~data['id'].isin(balanced_data['id'])]\n",
    "\n",
    "#filter out id with less than 20 images\n",
    "filtered_data = filtered_data.groupby('id').filter(lambda x: len(x) >= 20)\n",
    "\n",
    "#check number of id per race\n",
    "id_per_race = filtered_data.groupby('race')['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(filtered_data, \"./\", \"disjoint_balanced_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample biased datasets for each race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_by_race(race_data, id_per_race, image_per_id):\n",
    "    total_img = id_per_race * image_per_id\n",
    "\n",
    "    # Group by ID and count the number of images per ID\n",
    "    data_grouped = race_data.groupby(\"id\").count()\n",
    "    \n",
    "    # Get a list of IDs that meet the image count criteria\n",
    "    eligible_ids = data_grouped.index.tolist()\n",
    "    \n",
    "    # Shuffle the list of eligible IDs\n",
    "    random.shuffle(eligible_ids)\n",
    "    \n",
    "    # Take the first 'id_per_race' IDs to ensure uniform distribution\n",
    "    selected_ids = eligible_ids[:id_per_race]\n",
    "    \n",
    "    # Filter the DataFrame to include only rows with selected IDs\n",
    "    filtered_id_df = race_data[race_data[\"id\"].isin(selected_ids)]\n",
    "    \n",
    "    # Randomly sample images from each selected ID to meet the 'total_img' requirement\n",
    "    num_selected_images = 0\n",
    "    selected_rows = []\n",
    "    \n",
    "    for id in selected_ids:\n",
    "        id_df = filtered_id_df[filtered_id_df[\"id\"] == id]\n",
    "        num_images_for_id = min(image_per_id, total_img - num_selected_images)\n",
    "        \n",
    "        # Randomly sample 'num_images_for_id' images for the current ID\n",
    "        sampled_rows = id_df.sample(n=num_images_for_id, random_state=42)\n",
    "        selected_rows.extend(sampled_rows.values)\n",
    "        num_selected_images += num_images_for_id\n",
    "        \n",
    "        if num_selected_images >= total_img:\n",
    "            break\n",
    "    \n",
    "    # Create a new DataFrame from the selected rows\n",
    "    new_df = pd.DataFrame(selected_rows, columns=['image_name', 'id', 'race'])\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def generate_unbalanced_datasets(filtered_csv, output_dir, majority_num_ids=3600, minority_num_ids=780, image_per_id=20):\n",
    "    race_to_label = {'Caucasian': 0, 'Indian': 1, 'Asian': 2, 'African': 3}\n",
    "    label_to_race = {0: 'Caucasian', 1: 'Indian', 2: 'Asian', 3: 'African'}\n",
    "    \n",
    "    filtered_data = pd.read_csv(filtered_csv)\n",
    "    coloumns = ['image_name', 'id', 'race']\n",
    "\n",
    "    for race, label in race_to_label.items():\n",
    "        cur_label = label\n",
    "        cur_biased_data = pd.DataFrame(columns=coloumns)\n",
    "\n",
    "        for iter_label, _ in label_to_race.items():\n",
    "            if iter_label == cur_label:\n",
    "                majority_race = filtered_data[filtered_data['race'] == cur_label]\n",
    "                majority_sample = sample_by_race(majority_race, majority_num_ids, image_per_id)\n",
    "                cur_biased_data = pd.concat([cur_biased_data, majority_sample])\n",
    "            else:\n",
    "                minority_sample = filtered_data[filtered_data['race'] == iter_label]\n",
    "                minority_sample = sample_by_race(minority_sample, minority_num_ids, image_per_id)\n",
    "                cur_biased_data = pd.concat([cur_biased_data, minority_sample])\n",
    "\n",
    "        # Save the unbalanced data as CSV.\n",
    "        cur_biased_data.to_csv(f'{output_dir}/unbalanced_{race}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_unbalanced_datasets(\"./disjoint_balanced_data.csv\", \"./\", majority_num_ids=3600, minority_num_ids=780, image_per_id=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "african_unbalnced = pd.read_csv(\"./unbalanced_African.csv\")\n",
    "asian_unbalnced = pd.read_csv(\"./unbalanced_Asian.csv\")\n",
    "caucasian_unbalnced = pd.read_csv(\"./unbalanced_Caucasian.csv\")\n",
    "indian_unbalnced = pd.read_csv(\"./unbalanced_Indian.csv\")\n",
    "\n",
    "balanced_data = pd.read_csv(\"./balanced_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(african_unbalnced.groupby('id').count()['image_name'].value_counts())\n",
    "print(asian_unbalnced.groupby('id').count()['image_name'].value_counts())\n",
    "print(\"Caucasian unbalanced\", caucasian_unbalnced.groupby('id').count()['image_name'].value_counts())\n",
    "print(\"Indian unbalanced\", indian_unbalnced.groupby('id').count()['image_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_unbalnced.groupby('race')['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check identity leakage\n",
    "african_unbalnced_id = african_unbalnced['id'].tolist()\n",
    "asian_unbalnced_id = asian_unbalnced['id'].tolist()\n",
    "caucasian_unbalnced_id = caucasian_unbalnced['id'].tolist()\n",
    "indian_unbalnced_id = indian_unbalnced['id'].tolist()\n",
    "\n",
    "balanced_data_id = balanced_data['id'].tolist()\n",
    "\n",
    "print(\"number of identity overlap between african_unbalnced and balanced_data: \", len(set(african_unbalnced_id).intersection(balanced_data_id)))\n",
    "print(\"number of identity overlap between asian_unbalnced and balanced_data: \", len(set(asian_unbalnced_id).intersection(balanced_data_id)))\n",
    "print(\"number of identity overlap between caucasian_unbalnced and balanced_data: \", len(set(caucasian_unbalnced_id).intersection(balanced_data_id)))\n",
    "print(\"number of identity overlap between indian_unbalnced and balanced_data: \", len(set(indian_unbalnced_id).intersection(balanced_data_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Train and Test in Balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_train_test(data, percentage_test_per_id=0.2):\n",
    "    image_per_id = balanced_data.groupby('id').count()['image_name'][0]\n",
    "    num_test_per_id = (image_per_id * percentage_test_per_id).astype(int)\n",
    "\n",
    "    result_df = data.copy()\n",
    "    result_df['split'] = 'train'\n",
    "    unique_ids = data['id'].unique()\n",
    "\n",
    "    for id in unique_ids:\n",
    "        test_indices = data[data['id'] == id].head(num_test_per_id).index\n",
    "        result_df.loc[test_indices, 'split'] = 'test'\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/lw4c28nj0t9673hql45sbnp80000gn/T/ipykernel_98387/218188292.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  image_per_id = balanced_data.groupby('id').count()['image_name'][0]\n"
     ]
    }
   ],
   "source": [
    "balanced_data = pd.read_csv(\"./balanced_data.csv\")\n",
    "balanced_data = mark_train_test(balanced_data, 0.2)\n",
    "save_csv(balanced_data, \"./\", \"balanced_data_split.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data save to each race folder\n",
    "'''\n",
    "def save_test_image(identity_selection, data_path, save_path, label_to_race):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)    \n",
    "\n",
    "    identity_selection = identity_selection.copy()\n",
    "    identity_selection = identity_selection[identity_selection['split'] == 'test']\n",
    "\n",
    "    for _, row in tqdm(identity_selection.iterrows(), total=len(identity_selection), desc=\"Processing Images\"):\n",
    "        image_name = row['image_name']\n",
    "        id = row['id']\n",
    "        race = label_to_race[row['race']]\n",
    "\n",
    "        source_path = os.path.join(data_path, race, id, image_name)\n",
    "        #save to each race folder\n",
    "        race_path = os.path.join(save_path, race)\n",
    "\n",
    "        if not os.path.exists(race_path):\n",
    "            os.makedirs(race_path)\n",
    "\n",
    "        identity_save_path = os.path.join(race_path, id)\n",
    "\n",
    "        # Create a subdirectory for the identity if it doesn't exist\n",
    "        if not os.path.exists(identity_save_path):\n",
    "            os.makedirs(identity_save_path)\n",
    "\n",
    "        destination_path = os.path.join(identity_save_path, image_name.replace('.jpg', '.png'))\n",
    "        \n",
    "        # Check if the image already exists\n",
    "        if os.path.exists(destination_path):\n",
    "            continue\n",
    "\n",
    "        # Open the image and save it in PNG format\n",
    "        with Image.open(source_path) as img:\n",
    "            img.save(destination_path, \"PNG\")\n",
    "\n",
    "    print('Finished copying and converting images to folder')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./balanced_data_split.csv\")\n",
    "data_folder_path = \"./race_per_7000\"\n",
    "save_path = \"./\"\n",
    "\n",
    "\n",
    "race_to_label = {'Caucasian': 0, 'Indian': 1, 'Asian': 2, 'African': 3}\n",
    "label_to_race = {0: 'Caucasian', 1: 'Indian', 2: 'Asian', 3: 'African'}\n",
    "\n",
    "save_test_image(data, data_folder_path, save_path+'/test', label_to_race)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
