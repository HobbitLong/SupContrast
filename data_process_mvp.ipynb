{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "extract all identities that have more than #num_images/id images, \n",
    "then uniformally get num_identity identities from each race\n",
    "then uniformally get num_images/id images from each identity\n",
    "then split into train and test\n",
    "then resize data to 112*112\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "'''\n",
    "data frame: id_name, image_name, race \n",
    "data frame: id_name, id_name_count, image_name, race\n",
    "race: caucassian = 0, african = 1\n",
    "'''\n",
    "race_dict = {'caucasian': 0, 'african': 1}\n",
    "\n",
    "\n",
    "def get_dataset(race_folder, race, image_per_id= 10, image_per_id_limit=10):\n",
    "    coloumns = ['image_name', 'id', 'race']\n",
    "    balanced_dataset = []\n",
    "    race_idx = race_dict[race]\n",
    "\n",
    "    for id_folder in os.listdir(race_folder):\n",
    "        all_id_image = []\n",
    "\n",
    "        if not 'm.' in id_folder:\n",
    "            continue\n",
    "        id_path = os.path.join(race_folder, id_folder)\n",
    "        id = id_folder.split(\"/\")[0]\n",
    "\n",
    "        num_image = 0\n",
    "\n",
    "        for image in os.listdir(id_path):\n",
    "            num_image += 1\n",
    "        if num_image < image_per_id_limit:\n",
    "            continue\n",
    "        else:\n",
    "            for image in os.listdir(id_path):\n",
    "                image_path = os.path.join(id_path, image)\n",
    "                all_id_image.append(image)\n",
    "        uniform_subset = get_data_uniformly(all_id_image, image_per_id)\n",
    "\n",
    "        for i, image in enumerate(uniform_subset):\n",
    "            image_name = image\n",
    "            balanced_dataset.append([image_name, id, race_idx])\n",
    "    balanced_dataset = pd.DataFrame(balanced_dataset, columns=coloumns)\n",
    "    return balanced_dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "caucassian_balanced_data = get_dataset('../ore_code/race_per_7000/Caucasian', 'caucasian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m.011_0k</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.011_pk</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.011m1y</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.011s_x</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0120mb</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0sw7b</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0t5w1q8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0tpbzwn</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0yd59</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0zdq</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6554 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name  race\n",
       "id                         \n",
       "m.011_0k           10    10\n",
       "m.011_pk           10    10\n",
       "m.011m1y           10    10\n",
       "m.011s_x           10    10\n",
       "m.0120mb           10    10\n",
       "...               ...   ...\n",
       "m.0sw7b            10    10\n",
       "m.0t5w1q8          10    10\n",
       "m.0tpbzwn          10    10\n",
       "m.0yd59            10    10\n",
       "m.0zdq             10    10\n",
       "\n",
       "[6554 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group by id and show how many id\n",
    "caucassian_balanced_data.groupby('id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_identity_uniformly(data, num_id=3000):\n",
    "    id_list = data['id'].unique()\n",
    "    random_id_list = random.sample(list(id_list), num_id)\n",
    "    #get all data from random_id_list\n",
    "    random_choice = data[data['id'].isin(random_id_list)]\n",
    "    random_choice = random_choice.reset_index(drop=True)\n",
    "    return random_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "caucassian_identity_uniformly = pick_identity_uniformly(caucassian_balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(caucassian_identity_uniformly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_id_selection_per_race(identity_pd, save_path, file_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    identity_pd.to_csv(save_path + file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_id_selection_per_race(caucassian_identity_uniformly, save_path='./data', file_path='/caucassian_id_selection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in /Users/nina/Library/Python/3.9/lib/python/site-packages (10.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "def get_image_to_folder(identity_selection, data_path, save_path):\n",
    "    # Create the save_path directory if it doesn't exist\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    current_num_id = 0 \n",
    "\n",
    "    for _, row in identity_selection.iterrows():\n",
    "\n",
    "        current_num_id += 1\n",
    "\n",
    "        if current_num_id % 1000 == 0:\n",
    "            print('Finished copying and converting {} images'.format(current_num_id))\n",
    "\n",
    "        image_name = row['image_name']\n",
    "        identity = row['id']\n",
    "        source_path = os.path.join(data_path, identity, image_name)\n",
    "        identity_save_path = os.path.join(save_path, identity)\n",
    "\n",
    "        # Create a subdirectory for the identity if it doesn't exist\n",
    "        if not os.path.exists(identity_save_path):\n",
    "            os.makedirs(identity_save_path)\n",
    "\n",
    "        destination_path = os.path.join(identity_save_path, image_name.replace('.jpg', '.png'))\n",
    "\n",
    "        # Check if the image already exists\n",
    "        if os.path.exists(destination_path):\n",
    "            continue\n",
    "\n",
    "        # Open the image and save it in PNG format\n",
    "        with Image.open(source_path) as img:\n",
    "            img.save(destination_path, \"PNG\")\n",
    "        \n",
    "    print('Finished copying and converting images to folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished copying and converting 1000 images\n",
      "Finished copying and converting 2000 images\n",
      "Finished copying and converting 3000 images\n",
      "Finished copying and converting 4000 images\n",
      "Finished copying and converting 5000 images\n",
      "Finished copying and converting 6000 images\n",
      "Finished copying and converting 7000 images\n",
      "Finished copying and converting 8000 images\n",
      "Finished copying and converting 9000 images\n",
      "Finished copying and converting 10000 images\n",
      "Finished copying and converting 11000 images\n",
      "Finished copying and converting 12000 images\n",
      "Finished copying and converting 13000 images\n",
      "Finished copying and converting 14000 images\n",
      "Finished copying and converting 15000 images\n",
      "Finished copying and converting 16000 images\n",
      "Finished copying and converting 17000 images\n",
      "Finished copying and converting 18000 images\n",
      "Finished copying and converting 19000 images\n",
      "Finished copying and converting 20000 images\n",
      "Finished copying and converting 21000 images\n",
      "Finished copying and converting 22000 images\n",
      "Finished copying and converting 23000 images\n",
      "Finished copying and converting 24000 images\n",
      "Finished copying and converting 25000 images\n",
      "Finished copying and converting 26000 images\n",
      "Finished copying and converting 27000 images\n",
      "Finished copying and converting 28000 images\n",
      "Finished copying and converting 29000 images\n",
      "Finished copying and converting 30000 images\n",
      "Finished copying and converting images to folder\n"
     ]
    }
   ],
   "source": [
    "get_image_to_folder(caucassian_identity_uniformly, \n",
    "                    data_path='/Users/nina/Desktop/ore_code/race_per_7000/Caucasian', \n",
    "                    save_path='./data/caucassian_id_selection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_balanced_data = get_dataset('../ore_code/race_per_7000/african', 'african')\n",
    "african_identity_uniformly = pick_identity_uniformly(african_balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(african_identity_uniformly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get folder for african_id_selection\n",
    "save_id_selection_per_race(african_identity_uniformly, save_path='./data', file_path='/african_id_selection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished copying and converting 1000 images\n",
      "Finished copying and converting 2000 images\n",
      "Finished copying and converting 3000 images\n",
      "Finished copying and converting 4000 images\n",
      "Finished copying and converting 5000 images\n",
      "Finished copying and converting 6000 images\n",
      "Finished copying and converting 7000 images\n",
      "Finished copying and converting 8000 images\n",
      "Finished copying and converting 9000 images\n",
      "Finished copying and converting 10000 images\n",
      "Finished copying and converting 11000 images\n",
      "Finished copying and converting 12000 images\n",
      "Finished copying and converting 13000 images\n",
      "Finished copying and converting 14000 images\n",
      "Finished copying and converting 15000 images\n",
      "Finished copying and converting 16000 images\n",
      "Finished copying and converting 17000 images\n",
      "Finished copying and converting 18000 images\n",
      "Finished copying and converting 19000 images\n",
      "Finished copying and converting 20000 images\n",
      "Finished copying and converting 21000 images\n",
      "Finished copying and converting 22000 images\n",
      "Finished copying and converting 23000 images\n",
      "Finished copying and converting 24000 images\n",
      "Finished copying and converting 25000 images\n",
      "Finished copying and converting 26000 images\n",
      "Finished copying and converting 27000 images\n",
      "Finished copying and converting 28000 images\n",
      "Finished copying and converting 29000 images\n",
      "Finished copying and converting 30000 images\n",
      "Finished copying and converting images to folder\n"
     ]
    }
   ],
   "source": [
    "get_image_to_folder(african_identity_uniformly, \n",
    "                    data_path='/Users/nina/Desktop/ore_code/race_per_7000/African', \n",
    "                    save_path='./data/african_id_selection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(identity_selection, save_path, file_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    identity_selection.to_csv(save_path + file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_data_uniformly(data, num_image=10):\n",
    "    random_choce = random.sample(data, num_image)\n",
    "    return random_choce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_data(folder_path,race, race_label, image_per_id= 10):\n",
    "    coloumns = ['image_name', 'id', 'race']\n",
    "    race_folder = os.path.join(folder_path, race)\n",
    "    balanced_dataset = []\n",
    "\n",
    "    for id_folder in os.listdir(race_folder):\n",
    "        all_id_image = []\n",
    "\n",
    "        if not 'm.' in id_folder:\n",
    "            continue\n",
    "        id_path = os.path.join(race_folder, id_folder)\n",
    "        id = id_folder.split(\"/\")[0]\n",
    "\n",
    "        num_image = 0\n",
    "\n",
    "        for image in os.listdir(id_path):\n",
    "            num_image += 1\n",
    "        if num_image < image_per_id:\n",
    "            continue\n",
    "        else:\n",
    "            for image in os.listdir(id_path):\n",
    "                image_path = os.path.join(id_path, image)\n",
    "                all_id_image.append(image)\n",
    "        uniform_subset = get_data_uniformly(all_id_image, image_per_id)\n",
    "\n",
    "        for i, image in enumerate(uniform_subset):\n",
    "            image_name = image\n",
    "            balanced_dataset.append([image_name, id, race_label])\n",
    "    balanced_dataset = pd.DataFrame(balanced_dataset, columns=coloumns)\n",
    "    return balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_identity_uniformly(data, num_id=3000):\n",
    "    id_list = data['id'].unique()\n",
    "    random_id_list = random.sample(list(id_list), num_id)\n",
    "    #get all data from random_id_list\n",
    "    random_choice = data[data['id'].isin(random_id_list)]\n",
    "    random_choice = random_choice.reset_index(drop=True)\n",
    "    return random_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_select(folder_path, race, race_label, image_per_id=10, num_id=3000):\n",
    "    print(\"Selecting IDs from\", race)\n",
    "    balanced_data = get_balanced_data(folder_path, race, race_label, image_per_id)\n",
    "    identity_selection = pick_identity_uniformly(balanced_data, num_id)\n",
    "    return identity_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_train_test(identity_selection, num_test_per_id=2):\n",
    "    result_df = identity_selection.copy()\n",
    "    result_df['split'] = 'train'\n",
    "    unique_ids = identity_selection['id'].unique()\n",
    "\n",
    "    for id in unique_ids:\n",
    "        test_indices = identity_selection[identity_selection['id'] == id].head(num_test_per_id).index\n",
    "        result_df.loc[test_indices, 'split'] = 'test'\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def save_train_image(identity_selection, data_path, save_path, label_to_race):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for _, row in tqdm(identity_selection.iterrows(), total=len(identity_selection), desc=\"Processing Images\"):\n",
    "        if row['split'] == 'test':\n",
    "            continue\n",
    "\n",
    "        image_name = row['image_name']\n",
    "        id = row['id']\n",
    "        race = label_to_race[row['race']]\n",
    "\n",
    "        source_path = os.path.join(data_path, race, id, image_name)\n",
    "        identity_save_path = os.path.join(save_path, id)\n",
    "\n",
    "        # Create a subdirectory for the identity if it doesn't exist\n",
    "        if not os.path.exists(identity_save_path):\n",
    "            os.makedirs(identity_save_path)\n",
    "\n",
    "        destination_path = os.path.join(identity_save_path, image_name.replace('.jpg', '.png'))\n",
    "        \n",
    "        # Check if the image already exists\n",
    "        if os.path.exists(destination_path):\n",
    "            continue\n",
    "\n",
    "        # Open the image and save it in PNG format\n",
    "        with Image.open(source_path) as img:\n",
    "            img.save(destination_path, \"PNG\")\n",
    "\n",
    "    print('Finished copying and converting images to folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_image():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_balanced_data(data_folder_path, save_path, image_per_id=10, num_id=3000):\n",
    "    #get identity from each race \n",
    "    race_to_label = {'Caucasian': 0, 'African': 1}\n",
    "    label_to_race = {0: 'Caucasian', 1: 'African'}\n",
    "\n",
    "    race_id_select = pd.DataFrame()\n",
    "    data_folder_path = data_folder_path + '/'\n",
    "\n",
    "    for race in race_to_label.keys():\n",
    "\n",
    "        race_label=race_to_label[race]\n",
    "\n",
    "        id_select = get_id_select(data_folder_path, race, race_label, image_per_id, num_id)\n",
    "        \n",
    "        #mark train and test\n",
    "        id_select = mark_train_test(id_select)\n",
    "        \n",
    "        race_id_select = pd.concat([race_id_select, id_select])\n",
    "    \n",
    "    #save race_id_select to csv\n",
    "    save_csv(race_id_select, save_path, 'data.csv')\n",
    "    \n",
    "    #save train and test image to folder\n",
    "    save_train_image(race_id_select, data_folder_path, save_path, label_to_race)\n",
    "    # save_test_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting IDs from Caucasian\n",
      "Selecting IDs from African\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1143it [00:50, 22.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/ImageFile.py:515\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 515\u001b[0m     fh \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mfileno()\n\u001b[1;32m    516\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m image_per_id \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m num_id \u001b[39m=\u001b[39m \u001b[39m3000\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m make_balanced_data(data_folder_path, save_path, image_per_id, num_id)\n",
      "\u001b[1;32m/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb Cell 27\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m save_csv(race_id_select, save_path, \u001b[39m'\u001b[39m\u001b[39mdata.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#save train and test image to folder\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m save_train_image(race_id_select, data_folder_path, save_path, label_to_race)\n",
      "\u001b[1;32m/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb Cell 27\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# Open the image and save it in PNG format\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mwith\u001b[39;00m Image\u001b[39m.\u001b[39mopen(source_path) \u001b[39mas\u001b[39;00m img:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         img\u001b[39m.\u001b[39;49msave(destination_path, \u001b[39m\"\u001b[39;49m\u001b[39mPNG\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFinished copying and converting images to folder\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/Image.py:2413\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2410\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mw+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2412\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2413\u001b[0m     save_handler(\u001b[39mself\u001b[39;49m, fp, filename)\n\u001b[1;32m   2414\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   2415\u001b[0m     \u001b[39mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/PngImagePlugin.py:1398\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1396\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n\u001b[1;32m   1397\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1398\u001b[0m     ImageFile\u001b[39m.\u001b[39;49m_save(im, _idat(fp, chunk), [(\u001b[39m\"\u001b[39;49m\u001b[39mzip\u001b[39;49m\u001b[39m\"\u001b[39;49m, (\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m) \u001b[39m+\u001b[39;49m im\u001b[39m.\u001b[39;49msize, \u001b[39m0\u001b[39;49m, rawmode)])\n\u001b[1;32m   1400\u001b[0m \u001b[39mif\u001b[39;00m info:\n\u001b[1;32m   1401\u001b[0m     \u001b[39mfor\u001b[39;00m info_chunk \u001b[39min\u001b[39;00m info\u001b[39m.\u001b[39mchunks:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/ImageFile.py:519\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    518\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation) \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 519\u001b[0m     _encode_tile(im, fp, tile, bufsize, \u001b[39mNone\u001b[39;49;00m, exc)\n\u001b[1;32m    520\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(fp, \u001b[39m\"\u001b[39m\u001b[39mflush\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    521\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/ImageFile.py:538\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mif\u001b[39;00m exc:\n\u001b[1;32m    536\u001b[0m     \u001b[39m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m         errcode, data \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mencode(bufsize)[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    539\u001b[0m         fp\u001b[39m.\u001b[39mwrite(data)\n\u001b[1;32m    540\u001b[0m         \u001b[39mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TODO: move data to cur folder\n",
    "data_folder_path = '/Users/nina/Desktop/ore_code/race_per_7000'\n",
    "save_path = './data/train'\n",
    "image_per_id = 10\n",
    "num_id = 3000\n",
    "make_balanced_data(data_folder_path, save_path, image_per_id, num_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
