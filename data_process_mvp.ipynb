{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "extract all identities that have more than #num_images/id images, \n",
    "then uniformally get num_identity identities from each race\n",
    "then uniformally get num_images/id images from each identity\n",
    "then split into train and test\n",
    "then resize data to 112*112\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_data_uniformly(data, num_image=10):\n",
    "    random_choce = random.sample(data, num_image)\n",
    "    return random_choce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "'''\n",
    "data frame: id_name, image_name, race \n",
    "data frame: id_name, id_name_count, image_name, race\n",
    "race: caucassian = 0, african = 1\n",
    "'''\n",
    "race_dict = {'caucasian': 0, 'african': 1}\n",
    "\n",
    "\n",
    "def get_dataset(race_folder, race, image_per_id= 10, image_per_id_limit=10):\n",
    "    coloumns = ['image_name', 'id', 'race']\n",
    "    balanced_dataset = []\n",
    "    race_idx = race_dict[race]\n",
    "\n",
    "    for id_folder in os.listdir(race_folder):\n",
    "        all_id_image = []\n",
    "\n",
    "        if not 'm.' in id_folder:\n",
    "            continue\n",
    "        id_path = os.path.join(race_folder, id_folder)\n",
    "        id = id_folder.split(\"/\")[0]\n",
    "\n",
    "        num_image = 0\n",
    "\n",
    "        for image in os.listdir(id_path):\n",
    "            num_image += 1\n",
    "        if num_image < image_per_id_limit:\n",
    "            continue\n",
    "        else:\n",
    "            for image in os.listdir(id_path):\n",
    "                image_path = os.path.join(id_path, image)\n",
    "                all_id_image.append(image)\n",
    "        uniform_subset = get_data_uniformly(all_id_image, image_per_id)\n",
    "\n",
    "        for i, image in enumerate(uniform_subset):\n",
    "            image_name = image\n",
    "            balanced_dataset.append([image_name, id, race_idx])\n",
    "    balanced_dataset = pd.DataFrame(balanced_dataset, columns=coloumns)\n",
    "    return balanced_dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "caucassian_balanced_data = get_dataset('../ore_code/race_per_7000/Caucasian', 'caucasian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m.011_0k</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.011_pk</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.011m1y</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.011s_x</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0120mb</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0sw7b</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0t5w1q8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0tpbzwn</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0yd59</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0zdq</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6554 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name  race\n",
       "id                         \n",
       "m.011_0k           10    10\n",
       "m.011_pk           10    10\n",
       "m.011m1y           10    10\n",
       "m.011s_x           10    10\n",
       "m.0120mb           10    10\n",
       "...               ...   ...\n",
       "m.0sw7b            10    10\n",
       "m.0t5w1q8          10    10\n",
       "m.0tpbzwn          10    10\n",
       "m.0yd59            10    10\n",
       "m.0zdq             10    10\n",
       "\n",
       "[6554 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group by id and show how many id\n",
    "caucassian_balanced_data.groupby('id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pick identity uniformly from pd\n",
    "'''\n",
    "def pick_identity_uniformly(data, num_id=3000):\n",
    "    id_list = data['id'].unique()\n",
    "    random_id_list = random.sample(list(id_list), num_id)\n",
    "    #get all data from random_id_list\n",
    "    random_choice = data[data['id'].isin(random_id_list)]\n",
    "    random_choice = random_choice.reset_index(drop=True)\n",
    "    return random_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "caucassian_identity_uniformly = pick_identity_uniformly(caucassian_balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(caucassian_identity_uniformly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_id_selection_per_race(identity_pd, save_path, file_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    identity_pd.to_csv(save_path + file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_id_selection_per_race(caucassian_identity_uniformly, save_path='./data', file_path='/caucassian_id_selection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in /Users/nina/Library/Python/3.9/lib/python/site-packages (10.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "def get_image_to_folder(identity_selection, data_path, save_path):\n",
    "    # Create the save_path directory if it doesn't exist\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    current_num_id = 0 \n",
    "\n",
    "    for _, row in identity_selection.iterrows():\n",
    "\n",
    "        current_num_id += 1\n",
    "\n",
    "        if current_num_id % 1000 == 0:\n",
    "            print('Finished copying and converting {} images'.format(current_num_id))\n",
    "\n",
    "        image_name = row['image_name']\n",
    "        identity = row['id']\n",
    "        source_path = os.path.join(data_path, identity, image_name)\n",
    "        identity_save_path = os.path.join(save_path, identity)\n",
    "\n",
    "        # Create a subdirectory for the identity if it doesn't exist\n",
    "        if not os.path.exists(identity_save_path):\n",
    "            os.makedirs(identity_save_path)\n",
    "\n",
    "        destination_path = os.path.join(identity_save_path, image_name.replace('.jpg', '.png'))\n",
    "\n",
    "        # Check if the image already exists\n",
    "        if os.path.exists(destination_path):\n",
    "            continue\n",
    "\n",
    "        # Open the image and save it in PNG format\n",
    "        with Image.open(source_path) as img:\n",
    "            img.save(destination_path, \"PNG\")\n",
    "        \n",
    "\n",
    "\n",
    "    print('Finished copying and converting images to folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/ImageFile.py:515\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 515\u001b[0m     fh \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mfileno()\n\u001b[1;32m    516\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_image_to_folder(caucassian_identity_uniformly, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                     data_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/Users/nina/Desktop/ore_code/race_per_7000/Caucasian\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     save_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/caucassian_id_selection/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Open the image and save it in PNG format\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mwith\u001b[39;00m Image\u001b[39m.\u001b[39mopen(source_path) \u001b[39mas\u001b[39;00m img:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     img\u001b[39m.\u001b[39;49msave(destination_path, \u001b[39m\"\u001b[39;49m\u001b[39mPNG\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m current_num_id \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mif\u001b[39;00m current_num_id \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/Image.py:2413\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2410\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mw+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2412\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2413\u001b[0m     save_handler(\u001b[39mself\u001b[39;49m, fp, filename)\n\u001b[1;32m   2414\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   2415\u001b[0m     \u001b[39mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/PngImagePlugin.py:1398\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1396\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n\u001b[1;32m   1397\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1398\u001b[0m     ImageFile\u001b[39m.\u001b[39;49m_save(im, _idat(fp, chunk), [(\u001b[39m\"\u001b[39;49m\u001b[39mzip\u001b[39;49m\u001b[39m\"\u001b[39;49m, (\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m) \u001b[39m+\u001b[39;49m im\u001b[39m.\u001b[39;49msize, \u001b[39m0\u001b[39;49m, rawmode)])\n\u001b[1;32m   1400\u001b[0m \u001b[39mif\u001b[39;00m info:\n\u001b[1;32m   1401\u001b[0m     \u001b[39mfor\u001b[39;00m info_chunk \u001b[39min\u001b[39;00m info\u001b[39m.\u001b[39mchunks:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/ImageFile.py:519\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    518\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation) \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m--> 519\u001b[0m     _encode_tile(im, fp, tile, bufsize, \u001b[39mNone\u001b[39;49;00m, exc)\n\u001b[1;32m    520\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(fp, \u001b[39m\"\u001b[39m\u001b[39mflush\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    521\u001b[0m     fp\u001b[39m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/PIL/ImageFile.py:538\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mif\u001b[39;00m exc:\n\u001b[1;32m    536\u001b[0m     \u001b[39m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m         errcode, data \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mencode(bufsize)[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    539\u001b[0m         fp\u001b[39m.\u001b[39mwrite(data)\n\u001b[1;32m    540\u001b[0m         \u001b[39mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_image_to_folder(caucassian_identity_uniformly, \n",
    "                    data_path='/Users/nina/Desktop/ore_code/race_per_7000/Caucasian', \n",
    "                    save_path='./data/caucassian_id_selection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_balanced_data = get_dataset('../ore_code/race_per_7000/african', 'african')\n",
    "african_identity_uniformly = pick_identity_uniformly(african_balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(african_identity_uniformly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get folder for african_id_selection\n",
    "save_id_selection_per_race(african_identity_uniformly, save_path='./data', file_path='/african_id_selection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished copying images to folder\n"
     ]
    }
   ],
   "source": [
    "get_image_to_folder(african_identity_uniformly, \n",
    "                    data_path='/Users/nina/Desktop/ore_code/race_per_7000/African', \n",
    "                    save_path='./data/african_id_selection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
