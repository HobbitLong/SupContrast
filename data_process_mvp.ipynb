{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "extract all identities that have more than #num_images/id images, \n",
    "then uniformally get num_identity identities from each race\n",
    "then uniformally get num_images/id images from each identity\n",
    "then split into train and test\n",
    "then resize data to 112*112\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "'''\n",
    "data frame: id_name, image_name, race \n",
    "data frame: id_name, id_name_count, image_name, race\n",
    "race: caucassian = 0, african = 1\n",
    "'''\n",
    "race_dict = {'caucasian': 0, 'african': 1}\n",
    "\n",
    "\n",
    "def get_dataset(race_folder, race, image_per_id= 10, image_per_id_limit=10):\n",
    "    coloumns = ['image_name', 'id', 'race']\n",
    "    balanced_dataset = []\n",
    "    race_idx = race_dict[race]\n",
    "\n",
    "    for id_folder in os.listdir(race_folder):\n",
    "        all_id_image = []\n",
    "\n",
    "        if not 'm.' in id_folder:\n",
    "            continue\n",
    "        id_path = os.path.join(race_folder, id_folder)\n",
    "        id = id_folder.split(\"/\")[0]\n",
    "\n",
    "        num_image = 0\n",
    "\n",
    "        for image in os.listdir(id_path):\n",
    "            num_image += 1\n",
    "        if num_image < image_per_id_limit:\n",
    "            continue\n",
    "        else:\n",
    "            for image in os.listdir(id_path):\n",
    "                image_path = os.path.join(id_path, image)\n",
    "                all_id_image.append(image)\n",
    "        uniform_subset = get_data_uniformly(all_id_image, image_per_id)\n",
    "\n",
    "        for i, image in enumerate(uniform_subset):\n",
    "            image_name = image\n",
    "            balanced_dataset.append([image_name, id, race_idx])\n",
    "    balanced_dataset = pd.DataFrame(balanced_dataset, columns=coloumns)\n",
    "    return balanced_dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "caucassian_balanced_data = get_dataset('../ore_code/race_per_7000/Caucasian', 'caucasian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m.011_0k</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.011_pk</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.011m1y</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.011s_x</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0120mb</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0sw7b</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0t5w1q8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0tpbzwn</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0yd59</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m.0zdq</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6554 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name  race\n",
       "id                         \n",
       "m.011_0k           10    10\n",
       "m.011_pk           10    10\n",
       "m.011m1y           10    10\n",
       "m.011s_x           10    10\n",
       "m.0120mb           10    10\n",
       "...               ...   ...\n",
       "m.0sw7b            10    10\n",
       "m.0t5w1q8          10    10\n",
       "m.0tpbzwn          10    10\n",
       "m.0yd59            10    10\n",
       "m.0zdq             10    10\n",
       "\n",
       "[6554 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group by id and show how many id\n",
    "caucassian_balanced_data.groupby('id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_identity_uniformly(data, num_id=3000):\n",
    "    id_list = data['id'].unique()\n",
    "    random_id_list = random.sample(list(id_list), num_id)\n",
    "    #get all data from random_id_list\n",
    "    random_choice = data[data['id'].isin(random_id_list)]\n",
    "    random_choice = random_choice.reset_index(drop=True)\n",
    "    return random_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "caucassian_identity_uniformly = pick_identity_uniformly(caucassian_balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(caucassian_identity_uniformly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_id_selection_per_race(identity_pd, save_path, file_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    identity_pd.to_csv(save_path + file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_id_selection_per_race(caucassian_identity_uniformly, save_path='./data', file_path='/caucassian_id_selection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in /Users/nina/Library/Python/3.9/lib/python/site-packages (10.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "def get_image_to_folder(identity_selection, data_path, save_path):\n",
    "    # Create the save_path directory if it doesn't exist\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    current_num_id = 0 \n",
    "\n",
    "    for _, row in identity_selection.iterrows():\n",
    "\n",
    "        current_num_id += 1\n",
    "\n",
    "        if current_num_id % 1000 == 0:\n",
    "            print('Finished copying and converting {} images'.format(current_num_id))\n",
    "\n",
    "        image_name = row['image_name']\n",
    "        identity = row['id']\n",
    "        source_path = os.path.join(data_path, identity, image_name)\n",
    "        identity_save_path = os.path.join(save_path, identity)\n",
    "\n",
    "        # Create a subdirectory for the identity if it doesn't exist\n",
    "        if not os.path.exists(identity_save_path):\n",
    "            os.makedirs(identity_save_path)\n",
    "\n",
    "        destination_path = os.path.join(identity_save_path, image_name.replace('.jpg', '.png'))\n",
    "\n",
    "        # Check if the image already exists\n",
    "        if os.path.exists(destination_path):\n",
    "            continue\n",
    "\n",
    "        # Open the image and save it in PNG format\n",
    "        with Image.open(source_path) as img:\n",
    "            img.save(destination_path, \"PNG\")\n",
    "        \n",
    "    print('Finished copying and converting images to folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished copying and converting 1000 images\n",
      "Finished copying and converting 2000 images\n",
      "Finished copying and converting 3000 images\n",
      "Finished copying and converting 4000 images\n",
      "Finished copying and converting 5000 images\n",
      "Finished copying and converting 6000 images\n",
      "Finished copying and converting 7000 images\n",
      "Finished copying and converting 8000 images\n",
      "Finished copying and converting 9000 images\n",
      "Finished copying and converting 10000 images\n",
      "Finished copying and converting 11000 images\n",
      "Finished copying and converting 12000 images\n",
      "Finished copying and converting 13000 images\n",
      "Finished copying and converting 14000 images\n",
      "Finished copying and converting 15000 images\n",
      "Finished copying and converting 16000 images\n",
      "Finished copying and converting 17000 images\n",
      "Finished copying and converting 18000 images\n",
      "Finished copying and converting 19000 images\n",
      "Finished copying and converting 20000 images\n",
      "Finished copying and converting 21000 images\n",
      "Finished copying and converting 22000 images\n",
      "Finished copying and converting 23000 images\n",
      "Finished copying and converting 24000 images\n",
      "Finished copying and converting 25000 images\n",
      "Finished copying and converting 26000 images\n",
      "Finished copying and converting 27000 images\n",
      "Finished copying and converting 28000 images\n",
      "Finished copying and converting 29000 images\n",
      "Finished copying and converting 30000 images\n",
      "Finished copying and converting images to folder\n"
     ]
    }
   ],
   "source": [
    "get_image_to_folder(caucassian_identity_uniformly, \n",
    "                    data_path='/Users/nina/Desktop/ore_code/race_per_7000/Caucasian', \n",
    "                    save_path='./data/caucassian_id_selection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_balanced_data = get_dataset('../ore_code/race_per_7000/african', 'african')\n",
    "african_identity_uniformly = pick_identity_uniformly(african_balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(african_identity_uniformly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get folder for african_id_selection\n",
    "save_id_selection_per_race(african_identity_uniformly, save_path='./data', file_path='/african_id_selection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished copying and converting 1000 images\n",
      "Finished copying and converting 2000 images\n",
      "Finished copying and converting 3000 images\n",
      "Finished copying and converting 4000 images\n",
      "Finished copying and converting 5000 images\n",
      "Finished copying and converting 6000 images\n",
      "Finished copying and converting 7000 images\n",
      "Finished copying and converting 8000 images\n",
      "Finished copying and converting 9000 images\n",
      "Finished copying and converting 10000 images\n",
      "Finished copying and converting 11000 images\n",
      "Finished copying and converting 12000 images\n",
      "Finished copying and converting 13000 images\n",
      "Finished copying and converting 14000 images\n",
      "Finished copying and converting 15000 images\n",
      "Finished copying and converting 16000 images\n",
      "Finished copying and converting 17000 images\n",
      "Finished copying and converting 18000 images\n",
      "Finished copying and converting 19000 images\n",
      "Finished copying and converting 20000 images\n",
      "Finished copying and converting 21000 images\n",
      "Finished copying and converting 22000 images\n",
      "Finished copying and converting 23000 images\n",
      "Finished copying and converting 24000 images\n",
      "Finished copying and converting 25000 images\n",
      "Finished copying and converting 26000 images\n",
      "Finished copying and converting 27000 images\n",
      "Finished copying and converting 28000 images\n",
      "Finished copying and converting 29000 images\n",
      "Finished copying and converting 30000 images\n",
      "Finished copying and converting images to folder\n"
     ]
    }
   ],
   "source": [
    "get_image_to_folder(african_identity_uniformly, \n",
    "                    data_path='/Users/nina/Desktop/ore_code/race_per_7000/African', \n",
    "                    save_path='./data/african_id_selection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(identity_selection, save_path, file_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    identity_selection.to_csv(save_path + file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_data_uniformly(data, num_image=10):\n",
    "    random_choce = random.sample(data, num_image)\n",
    "    return random_choce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_data(folder_path,race, race_label, image_per_id= 10):\n",
    "    coloumns = ['image_name', 'id', 'race']\n",
    "    race_folder = os.path.join(folder_path, race)\n",
    "    balanced_dataset = []\n",
    "\n",
    "    for id_folder in os.listdir(race_folder):\n",
    "        all_id_image = []\n",
    "\n",
    "        if not 'm.' in id_folder:\n",
    "            continue\n",
    "        id_path = os.path.join(race_folder, id_folder)\n",
    "        id = id_folder.split(\"/\")[0]\n",
    "\n",
    "        num_image = 0\n",
    "\n",
    "        for image in os.listdir(id_path):\n",
    "            num_image += 1\n",
    "        if num_image < image_per_id:\n",
    "            continue\n",
    "        else:\n",
    "            for image in os.listdir(id_path):\n",
    "                image_path = os.path.join(id_path, image)\n",
    "                all_id_image.append(image)\n",
    "        uniform_subset = get_data_uniformly(all_id_image, image_per_id)\n",
    "\n",
    "        for i, image in enumerate(uniform_subset):\n",
    "            image_name = image\n",
    "            balanced_dataset.append([image_name, id, race_label])\n",
    "    balanced_dataset = pd.DataFrame(balanced_dataset, columns=coloumns)\n",
    "    return balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_identity_uniformly(data, num_id=3000):\n",
    "    id_list = data['id'].unique()\n",
    "    random_id_list = random.sample(list(id_list), num_id)\n",
    "    #get all data from random_id_list\n",
    "    random_choice = data[data['id'].isin(random_id_list)]\n",
    "    random_choice = random_choice.reset_index(drop=True)\n",
    "    return random_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_select(folder_path, race, race_label, image_per_id=10, num_id=3000):\n",
    "    print(\"Selecting IDs from\", race)\n",
    "    balanced_data = get_balanced_data(folder_path, race, race_label, image_per_id)\n",
    "    identity_selection = pick_identity_uniformly(balanced_data, num_id)\n",
    "    return identity_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_train_test(identity_selection, num_test_per_id=2):\n",
    "    result_df = identity_selection.copy()\n",
    "    result_df['split'] = 'train'\n",
    "    unique_ids = identity_selection['id'].unique()\n",
    "\n",
    "    for id in unique_ids:\n",
    "        test_indices = identity_selection[identity_selection['id'] == id].head(num_test_per_id).index\n",
    "        result_df.loc[test_indices, 'split'] = 'test'\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def save_train_image(identity_selection, data_path, save_path, label_to_race):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    #make a copy of the identity_selection\n",
    "    identity_selection = identity_selection.copy()\n",
    "    identity_selection = identity_selection[identity_selection['split'] == 'train']\n",
    "\n",
    "    print(len(identity_selection))\n",
    "    return \n",
    "\n",
    "    for _, row in tqdm(identity_selection.iterrows(), total=len(identity_selection), desc=\"Processing Images\"):\n",
    "        image_name = row['image_name']\n",
    "        id = row['id']\n",
    "        race = label_to_race[row['race']]\n",
    "\n",
    "        source_path = os.path.join(data_path, race, id, image_name)\n",
    "        identity_save_path = os.path.join(save_path, id)\n",
    "\n",
    "        # Create a subdirectory for the identity if it doesn't exist\n",
    "        if not os.path.exists(identity_save_path):\n",
    "            os.makedirs(identity_save_path)\n",
    "\n",
    "        destination_path = os.path.join(identity_save_path, image_name.replace('.jpg', '.png'))\n",
    "        \n",
    "        # Check if the image already exists\n",
    "        if os.path.exists(destination_path):\n",
    "            continue\n",
    "\n",
    "        # Open the image and save it in PNG format\n",
    "        with Image.open(source_path) as img:\n",
    "            img.save(destination_path, \"PNG\")\n",
    "\n",
    "    print('Finished copying and converting images to folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data save to each race folder\n",
    "'''\n",
    "def save_test_image(identity_selection, data_path, save_path, label_to_race):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)    \n",
    "\n",
    "    identity_selection = identity_selection.copy()\n",
    "    identity_selection = identity_selection[identity_selection['split'] == 'test']\n",
    "\n",
    "    for _, row in tqdm(identity_selection.iterrows(), total=len(identity_selection), desc=\"Processing Images\"):\n",
    "        image_name = row['image_name']\n",
    "        id = row['id']\n",
    "        race = label_to_race[row['race']]\n",
    "\n",
    "        source_path = os.path.join(data_path, race, id, image_name)\n",
    "        #save to each race folder\n",
    "        race_path = os.path.join(save_path, race)\n",
    "\n",
    "        if not os.path.exists(race_path):\n",
    "            os.makedirs(race_path)\n",
    "\n",
    "        identity_save_path = os.path.join(race_path, id)\n",
    "\n",
    "        # Create a subdirectory for the identity if it doesn't exist\n",
    "        if not os.path.exists(identity_save_path):\n",
    "            os.makedirs(identity_save_path)\n",
    "\n",
    "        destination_path = os.path.join(identity_save_path, image_name.replace('.jpg', '.png'))\n",
    "        \n",
    "        # Check if the image already exists\n",
    "        if os.path.exists(destination_path):\n",
    "            continue\n",
    "\n",
    "        # Open the image and save it in PNG format\n",
    "        with Image.open(source_path) as img:\n",
    "            img.save(destination_path, \"PNG\")\n",
    "\n",
    "    print('Finished copying and converting images to folder')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_id_csv(data_folder_path, race_to_label, save_path, image_per_id=10, num_id=3000):\n",
    "    race_id_select = pd.DataFrame()\n",
    "    data_folder_path = data_folder_path + '/'\n",
    "\n",
    "    for race in race_to_label.keys():\n",
    "\n",
    "        race_label=race_to_label[race]\n",
    "\n",
    "        id_select = get_id_select(data_folder_path, race, race_label, image_per_id, num_id)\n",
    "        \n",
    "        #mark train and test\n",
    "        id_select = mark_train_test(id_select)\n",
    "        \n",
    "        race_id_select = pd.concat([race_id_select, id_select])\n",
    "\n",
    "    #save race_id_select to csv\n",
    "    save_csv(race_id_select, save_path+'/train', 'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#only when csv does not exist\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# save_id_csv(data_folder_path, race_to_label, save_path, image_per_id, num_id)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m race_id_select \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m./data/data.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m save_train_image(race_id_select, data_folder_path, save_path\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/train\u001b[39;49m\u001b[39m'\u001b[39;49m, label_to_race)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(race_id_select\u001b[39m.\u001b[39mhead())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# save_test_image(race_id_select, data_folder_path, save_path+'/test', label_to_race)\u001b[39;00m\n",
      "\u001b[1;32m/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb Cell 27\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#make a copy of the identity_selection\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m identity_selection \u001b[39m=\u001b[39m identity_selection\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m identity_selection \u001b[39m=\u001b[39m identity_selection[identity_selection[\u001b[39m'\u001b[39;49m\u001b[39msplit\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(identity_selection))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nina/Desktop/SupContrast-ORE/data_process_mvp.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "#TODO: move data to cur folder\n",
    "data_folder_path = '/Users/nina/Desktop/ore_code/race_per_7000'\n",
    "save_path = './data/'\n",
    "image_per_id = 10\n",
    "num_id = 3000\n",
    "\n",
    "race_to_label = {'Caucasian': 0, 'African': 1}\n",
    "label_to_race = {0: 'Caucasian', 1: 'African'}\n",
    "\n",
    "#only when csv does not exist\n",
    "# save_id_csv(data_folder_path, race_to_label, save_path, image_per_id, num_id)\n",
    "\n",
    "race_id_select = pd.read_csv('./data/data.csv')\n",
    "\n",
    "save_train_image(race_id_select, data_folder_path, save_path+'/train', label_to_race)\n",
    "\n",
    "print(race_id_select.head())\n",
    "# save_test_image(race_id_select, data_folder_path, save_path+'/test', label_to_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
